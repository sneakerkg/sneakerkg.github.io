---
permalink: /
title: ""
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

<p align="center">
  <img src="https://sneakerkg.github.io/images/life_compact_crop.jpg?raw=true" alt="Photo" style="width: 450px;"/>
</p>

Recent News
======
* I joined Nvidia to work on Autonomous Vehicle and Robotics!

* We will be hosting the tutorial of [Object-centric Representations in Computer Vision](https://object-centric-representation.github.io/object-centric-tutorial-2024/) in CVPR 2024. Stay tuned and see you in Seattle!

* ðŸš€ Exciting News! ðŸ“˜ Our latest survey paper is now released, presenting a comprehensive analysis of hallucination phenomena in multimodal large language models (MLLMs), also known as Large Vision-Language Models (LVLMs). ([Paper](https://arxiv.org/abs/2404.18930), [Resource Repo](https://github.com/showlab/Awesome-MLLM-Hallucination)).

* Two papers got accpeted to CVPR 2024: Adaptive Slot Attention ([Paper](https://assets.amazon.science/27/54/f1b20e154ff8ba8953d8e30d165b/adaptive-slot-attention-object-discovery-with-dynamic-slot-number.pdf), [Project Page](https://kfan21.github.io/AdaSlot/)), Learning for Transductive Threshold Calibration in Open-World Recognition ([Paper](https://arxiv.org/abs/2305.12039)).

* Introduce our ICLR 2024 work, ðŸ”¥Instruct Video-to-VideoðŸ”¥, an efficient approach for video editing that eliminates the need for per-video-per-model finetuning by constructing a synthetic paired video dataset. ([Paper](https://arxiv.org/abs/2311.00213), [Code](https://github.com/amazon-science/instruct-video-to-video))

* Four papers got accpeted to ICCV 2023: OC-MOT ([Paper](https://assets.amazon.science/4c/a4/5f7af328411084022d95b67bc16e/object-centric-multiple-object-tracking.pdf), [Code](https://github.com/amazon-science/object-centric-multiple-object-tracking)), Slot-Naming ([Paper](https://assets.amazon.science/df/c2/2e845de144b0b4707c2e95bc616e/unsupervised-open-vocabulary-object-localization-in-videos.pdf)), C2F-Seg([Paper](https://www.amazon.science/publications/coarse-to-fine-amodal-segmentation-with-shape-prior), [Project Page](https://jianxgao.github.io/C2F-Seg/)), EoRaS([Paper](https://assets.amazon.science/25/3f/86240b4d4b67b4fb837b03f51b3d/rethinking-amodal-video-segmentation-from-learning-supervised-signals-with-object-centric-representation.pdf)).

* One paper is accepted to ICLR 2023: Bridging the Gap to Real-World Object-Centric Learning. [Paper](https://arxiv.org/abs/2209.14860) link and [code](https://github.com/amazon-science/object-centric-learning-framework) link.

* One paper is accepted to NeurIPS 2022 (Spotlight): Self-supervised Amodal Video Object Segmentation. [Paper](https://www.amazon.science/publications/self-supervised-amodal-video-object-segmentation) link and [code](https://github.com/amazon-science/self-supervised-amodal-video-object-segmentation) link.

About Me
======
* I recently came back to the frontline of autonomous vehicle and robotics, working as a principal engineer at Nvidia.
* I was an Applied Science Manager at [Amazon Web Service](https://aws.amazon.com/) AI Shanghai Lablet, leading computer vision efforts. I play a lot with objects. In this period, I will be focusing on object-centric learning, visual-language model, graph neural network and causal representation learning, exploring and exploiting their usage in applications like video analysis, 3D vision, autonomous driving and robotics. I also contributed to the Graph Neural Network framework [DGL](https://www.dgl.ai/) and Object-centric Learning Framework [OCLF](https://github.com/amazon-science/object-centric-learning-framework).
* Before joining Amazon, I was a Staff Machine Learning Scientist at [Tesla Autopilot](https://www.tesla.com/autopilot) AI/Vision team, working with Dr. [Andrej Karpathy](https://karpathy.ai/). I was one of the major contributors of the Autopilot vision neural network stack and the task owner of Autopilot (Dynamic and Static) Object Detection during 2017 - 2020. My working items have been shipped into hundreds of thousands of Tesla cars worldwide during major Autopilot releases, contributing to Autopilot functionalities like Traffic-Aware Cruise Control, Auto Lane Change, [Automatic Emergency Braking](https://www.tesla.com/blog/model-3-earns-5-star-safety-rating-euro-ncap), [Navigation on Autopilot](https://www.tesla.com/blog/introducing-navigate-autopilot), [Smart Summon](https://electrek.co/2019/09/24/tesla-smart-summon-driverless-video/), etc.
* Prior to Tesla, I spent 3.25 years at Microsoft. I was a Software Engineer 2 at Microsoft [Bing](https://cn.bing.com/images/trending?form=Z9LH) Multimedia team (now under Microsoft AI & Research Org) working with Dr. [Linjun Yang](https://scholar.google.com/citations?user=cvgKxDQAAAAJ&hl=zh-CN), where I was working on Image-Text Semantic Embedding to contribute to functionalities like Image Annotation and Image Search in Bing Search Engine. And during my graduate years, I interned at Microsoft Research Asia, advised by Prof. [Zheng Zhang](https://shanghai.nyu.edu/academics/faculty/directory/zheng-zhang) and Dr. [Kuiyuan Yang](https://sites.google.com/site/kuiyuanyang/), where I was working on both training platform and vision applications of deep learning. I was a major contributor of the open-source deep learning training framework [Minerva](https://github.com/dmlc/minerva) and also contributed to the machine learning library [MXNet](https://github.com/apache/incubator-mxnet).
* I received M.S degree in Computer Science from [Wangxuan Institute Of Computer Technology](http://www.icst.pku.edu.cn/index.htm), [Peking University](https://www.pku.edu.cn/), advised by Prof. [Yuxin Peng](http://59.108.48.34/tiki/yuxinpeng/). And B.S degree in Computer Science from [Nankai University](https://www.nankai.edu.cn/).
* My enthusiasm is to apply machine learning to large-scale, life-changing technologies, currently with a focus on computer vision related applications.
